{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2121fb2-5d47-42ed-ad6b-dcd4b22c2435",
   "metadata": {},
   "source": [
    "## Settings\n",
    "Please set the variables according to your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e3d752-c085-4a15-9644-2861f4b0c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many pages from https://www.allsides.com/headline-roundups to crawl?\n",
    "PAGE_START = 1\n",
    "PAGE_END = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8595ab-ad00-435e-9d18-f92b0993609e",
   "metadata": {},
   "source": [
    "## Import of required Modules\n",
    "Make sure, that the imported moduls are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b078c40-20cc-46c4-9a09-2947812fcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.remote.webelement import WebElement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d1a88-6955-4e93-a558-54a8488e7697",
   "metadata": {},
   "source": [
    "#### set up Selenium and Chrome Driver \n",
    "We use selenium with Chrome and tested the scraper with the chromedriver. You need the latest version of the driver from https://chromedriver.chromium.org/. Alternatively, change to the driver to a driver of your preference.\n",
    "We set up the scraper to run in the background, if you wish to run it in regular window mode, remove the line  \"chrome_options.add_argument(\"--headless\")\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b6234d-8171-4a69-8547-4247ae6d3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromedriver setup\n",
    "\n",
    "serv = Service(r'driver/chromedriver') #path from 'which chromedriver'\n",
    "\n",
    "# test driver\n",
    "# for headless chrome mode\n",
    "chrome_options = Options()\n",
    "\n",
    "# remove this line if you do not wish to run in background \n",
    "# chrome_options.add_argument(\"--headless\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485ef6d",
   "metadata": {},
   "source": [
    "### Data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14eb0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Literal, List\n",
    "\n",
    "@dataclass\n",
    "class Article:\n",
    "    source: str\n",
    "    headline: str\n",
    "    link: str\n",
    "    rating_img: str\n",
    "    rating: Literal[\"left\", \"lean left\", \"center\", \"lean right\", \"right\"]\n",
    "    summary: str\n",
    "    image_link: str\n",
    "    news_type: str\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"source\": self.source,\n",
    "            \"headline\": self.headline,\n",
    "            \"link\": self.link,\n",
    "            \"rating_img\": self.rating_img,\n",
    "            \"rating\": self.rating,\n",
    "            \"summary\": self.summary,\n",
    "            \"image_link\": self.image_link,\n",
    "            \"news_type\": self.news_type,\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class Story:\n",
    "    date: str\n",
    "\n",
    "    headline: str\n",
    "    headline_link: str\n",
    "\n",
    "    topic: str\n",
    "    topic_link: str\n",
    "    tags: List[str] = field(default_factory=lambda: [])\n",
    "\n",
    "    summary: str = \"\"\n",
    "    \n",
    "    left: Article | None = None\n",
    "    center: Article | None = None\n",
    "    right: Article | None = None\n",
    "\n",
    "    more_left: List[Article] = field(default_factory=lambda: [])\n",
    "    more_center: List[Article] = field(default_factory=lambda: [])\n",
    "    more_right: List[Article] = field(default_factory=lambda: [])\n",
    "\n",
    "    def to_json(self):\n",
    "        return {\n",
    "            \"date\": self.date, \n",
    "            \"headline\": self.headline, \n",
    "            \"headline_link\": self.headline_link, \n",
    "            \"topic\": self.topic,\n",
    "            \"topic_link\": self.topic_link, \n",
    "            \"tags\": self.tags, \n",
    "            \"summary\": self.summary, \n",
    "            \"left\": self.left.to_json() if self.left else \"\",\n",
    "            \"center\": self.center.to_json() if self.center else \"\",\n",
    "            \"right\": self.right.to_json() if self.right else \"\",\n",
    "            \"more_left\": [entry.to_json() for entry in self.more_left],\n",
    "            \"more_center\": [entry.to_json() for entry in self.more_center],\n",
    "            \"more_right\": [entry.to_json() for entry in self.more_right],\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1dc8d1",
   "metadata": {},
   "source": [
    "### Retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb14042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brief_stories_on_page(driver: webdriver.Chrome) -> List[Story]:\n",
    "    \"\"\"Get stories from headline_roundup\n",
    "\n",
    "    Args:\n",
    "        driver (WebDriver): Webdriver with loaded overview page\n",
    "\n",
    "    Returns:\n",
    "        List[Story]: List of stories (without more detailed information (news articles...))\n",
    "    \"\"\"\n",
    "    stories: list[Story] = []\n",
    "\n",
    "    story_rows = driver.find_elements(By.CSS_SELECTOR, \".views-table tbody tr\")\n",
    "\n",
    "    # loop trough all news stories for the given date (range)\n",
    "    for row in story_rows:\n",
    "        cols = row.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "        headline = cols[0].find_element(By.CSS_SELECTOR, \"a\")\n",
    "        topic = cols[1].find_element(By.CSS_SELECTOR, \"a\")\n",
    "        date = cols[2].find_element(By.CSS_SELECTOR, \"span\").text\n",
    "\n",
    "        stories.append(Story(\n",
    "            date,\n",
    "            headline.text,\n",
    "            headline.get_attribute(\"href\"),\n",
    "            topic.text,\n",
    "            topic.get_attribute(\"href\")\n",
    "        ))\n",
    "    return stories\n",
    "    \n",
    "\n",
    "def get_article_information(section: WebElement) -> Article:\n",
    "    title = section.find_element(By.CSS_SELECTOR, \".news-title\")\n",
    "    source = section.find_element(By.CSS_SELECTOR, \".news-source span\")\n",
    "\n",
    "    try: \n",
    "        rating_img_link = section.find_element(By.CSS_SELECTOR, \".source-area img\").get_attribute(\"src\")\n",
    "    except:\n",
    "        rating_img_link = \"\"\n",
    "\n",
    "    rating = \"unknown\"\n",
    "    if \"bias-left\" in os.path.basename(rating_img_link):\n",
    "        rating = \"left\"\n",
    "    elif \"bias-leaning-left\" in os.path.basename(rating_img_link):\n",
    "        rating = \"lean left\"\n",
    "    elif \"bias-center\" in os.path.basename(rating_img_link):\n",
    "        rating = \"center\"\n",
    "    elif \"bias-leaning-right\" in os.path.basename(rating_img_link):\n",
    "        rating = \"lean right\"\n",
    "    elif \"bias-right\" in os.path.basename(rating_img_link):\n",
    "        rating = \"right\"\n",
    "    else: \n",
    "        print(f\"Rating in <{rating_img_link}> unknown\")\n",
    "\n",
    "    try:\n",
    "        image = section.find_element(By.CSS_SELECTOR, \".headline-roundup-image img\")\n",
    "        image_link = image.get_attribute(\"src\")\n",
    "    except:\n",
    "        image_link = \"\"\n",
    "    body = section.find_elements(By.CSS_SELECTOR, \".news-body .body-contents\")\n",
    "    summary = \"\"\n",
    "    for paragraph in body:\n",
    "        summary += f\"{paragraph.text}\\n\"\n",
    "    summary = summary.strip()\n",
    "\n",
    "    return Article(\n",
    "        source=source.text,\n",
    "        headline=title.text,\n",
    "        link=title.get_attribute(\"href\"),\n",
    "        rating_img=rating_img_link,\n",
    "        rating=rating,\n",
    "        summary=summary,\n",
    "        image_link=image_link,\n",
    "        news_type=\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_story_details(driver: webdriver.Chrome, stories: List[Story]):\n",
    "    \"\"\"Adds information from story page to each story in stories\n",
    "\n",
    "    Args:\n",
    "        driver (WebDriver): _description_\n",
    "        stories (List[Story]): List of stories without detailed information\n",
    "    \"\"\"\n",
    "    for i, story in enumerate(stories):\n",
    "        driver.get(story.headline_link)\n",
    "        print(f\"{i}/{len(stories)}: {story.headline_link}\")\n",
    "        wait = WebDriverWait(driver, 5)\n",
    "        wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.view-content')))\n",
    "\n",
    "        tags = driver.find_elements(By.CSS_SELECTOR, \".page-tags a\")\n",
    "        story.tags = [tag.text for tag in tags]\n",
    "\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, \".story-id-page-description p\")\n",
    "        for paragraph in paragraphs:\n",
    "            story.summary += f\"{paragraph.text}\\n\"\n",
    "        story.summary = story.summary.strip()\n",
    "\n",
    "        article_sections = driver.find_elements(By.CSS_SELECTOR, \".featured-coverage .news-item\")\n",
    "\n",
    "        for section in article_sections:\n",
    "            if \"left\" in section.get_attribute(\"class\"):\n",
    "                story.left = get_article_information(section)\n",
    "            if \"center\" in section.get_attribute(\"class\"):\n",
    "                story.center = get_article_information(section)\n",
    "            if \"right\" in section.get_attribute(\"class\"):\n",
    "                story.right = get_article_information(section)\n",
    "\n",
    "        \n",
    "        more_news = {\"left\": [], \"center\": [], \"right\": []}\n",
    "        for stance in more_news.keys():\n",
    "            news_articles = driver.find_elements(By.CSS_SELECTOR, f\".news-trio .news-item.{stance}\")\n",
    "            for entry in news_articles:\n",
    "                article = get_article_information(entry)\n",
    "                article.link = entry.find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "                article.news_type = entry.find_element(By.CSS_SELECTOR, \".news-type-label\").text\n",
    "                more_news[stance].append(article)\n",
    "\n",
    "        story.more_left = more_news[\"left\"]\n",
    "        story.more_center = more_news[\"center\"]\n",
    "        story.more_right = more_news[\"right\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153cf31-4c05-4b1c-8699-60ab5630dcd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Retrieve Article Links for Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1389d55b-9b73-42a8-83f9-a10b26caa7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.allsides.com/headline-roundups'\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638b3e0",
   "metadata": {},
   "source": [
    "### Get brief story information and links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ea153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = get_brief_stories_on_page(driver)\n",
    "for i in range(PAGE_START - 1, PAGE_END):\n",
    "    driver.get(f\"{url}?page={i}\")\n",
    "    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.views-field a')))\n",
    "    stories.extend(get_brief_stories_on_page(driver))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a020ae",
   "metadata": {},
   "source": [
    "### Fill in story information and articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c49a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/600: https://www.allsides.com/story/politics-whats-trumps-big-beautiful-bill\n",
      "1/600: https://www.allsides.com/story/foreign-policy-media-responses-trump-s-jet-qatar\n"
     ]
    }
   ],
   "source": [
    "get_story_details(driver, stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406db37-2bd7-47ad-bc56-b96cf6261513",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03df279",
   "metadata": {},
   "source": [
    "### Saving crawled data as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59656ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Define the path to the output folder\n",
    "output_folder = \"crawls\"\n",
    "\n",
    "# Check if the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    # If the folder does not exist, create it\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d-%H%M\")\n",
    "\n",
    "# Save crawl as pkl file\n",
    "with open(os.path.join(output_folder, f'{formatted_datetime}_allsides_crawl.pkl'), 'wb') as f:\n",
    "    pickle.dump(stories, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3e7ba-4156-462a-a7fe-cc342e1d1826",
   "metadata": {},
   "source": [
    "### Saving crawled data as jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fa116-c85d-43e6-b783-0034f1affb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(output_folder, f'{formatted_datetime}_allsides_crawl.jsonl'), 'w') as f:\n",
    "    for story in stories: \n",
    "        if not story:\n",
    "            continue\n",
    "        json.dump(story.to_json(), f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad391361-48ff-4e3c-bcda-40cc6b29f102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbias",
   "language": "python",
   "name": "qbias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
